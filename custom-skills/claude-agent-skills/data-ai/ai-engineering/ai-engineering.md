---
name: ai-engineering
description: This skill provides expertise in LLM application and RAG system development. This skill should be used for LLM integrations, RAG systems, prompt pipelines, vector search, agent orchestration, or AI-powered application development. Focuses on reliability and cost efficiency.
enforcement_level: HIGH
violation_consequence: LLM applications may fail, perform poorly, or be costly, leading to poor user experience or high operational costs
---

# AI Engineering

This skill provides comprehensive guidance for LLM applications and generative AI systems. It emphasizes reliability, cost efficiency, and production-ready implementations.

## Overview

AI engineering involves integrating LLMs, building RAG systems, optimizing prompts, and deploying AI-powered applications. This skill provides systematic approaches to LLM application development.

## Focus Areas

### LLM Integration

- OpenAI, Anthropic, open source or local models
- API integration and error handling
- Fallback mechanisms
- Token optimization

### RAG Systems

- Vector databases (Qdrant, Pinecone, Weaviate)
- Chunking strategies
- Embedding strategies
- Semantic search

### Prompt Engineering

- Prompt optimization
- Prompt templates
- Variable injection
- Prompt versioning

### Agent Frameworks

- LangChain patterns
- LangGraph patterns
- CrewAI patterns
- Agent orchestration

### Embedding Strategies

- Embedding models
- Semantic search
- Similarity search
- Hybrid search

### Token Optimization

- Token usage tracking
- Cost management
- Optimization techniques
- Budget monitoring

## Approach

1. Start with simple prompts, iterate based on outputs
2. Implement fallbacks for AI service failures
3. Monitor token usage and costs
4. Use structured outputs (JSON mode, function calling)
5. Test with edge cases and adversarial inputs

## Output Format

Provide:
- LLM integration code with error handling
- RAG pipeline with chunking strategy
- Prompt templates with variable injection
- Vector database setup and queries
- Token usage tracking and optimization
- Evaluation metrics for AI outputs

## Best Practices

- Focus on reliability and cost efficiency
- Include prompt versioning and A/B testing
- Monitor token usage continuously
- Implement proper error handling
- Test with edge cases

Focus on reliability and cost efficiency. Include prompt versioning and A/B testing.

